---
title: "Forecasting Volatility"
author: "Hannah de Nobrega"
date: "2023-10-05"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
pacman::p_load(tidyverse, devtools, FactoMineR, factoextra, broom, rmsfuns, readr, stochvol, tsBSS, psych, rugarch, rmgarch, forecast, tbl2xts, lubridate, PerformanceAnalytics, ggthemes, MTS, robustbase, cowplot, knitr)
# pacman::p_load_gh("Nicktz/fmxdat")


# load code scripts for functions
list.files('./R/code/', full.names = T, recursive = T) %>% 
  as.list() %>% 
  walk(~source(.))


data <- read_csv("data/quantathon_hannah.csv")
pcaseries <- data
PCA_AllData <- data


data %>% 
  gather(ticker, value, -date) %>% 
  ggplot()+
  geom_line(aes(date, value)) +
  facet_wrap(~ticker, scales = "free_y")

data %>% 
  gather(ticker, value, -date) %>%
  arrange(date) %>% 
  group_by(ticker) %>% 
  mutate(Return = log(Price) - log(lag(Price))) 

```

# All Assets 

```{r dendrogram}
# pcaseries <- all data 
# pcaseries must be in wide format
pcaseries <-  pcaseries[, colSums(is.na(pcaseries)) < nrow(pcaseries)]   # remove Columns with only NA
pcaseries[is.na(pcaseries)] <- 0

demean = scale(pcaseries[,-1], center = TRUE, scale = TRUE)
sigma <- cov(demean)

devtools::source_gist("https://gist.github.com/Nicktz/bd2614f8f8a551881a1dc3c11a1e7268")
cluster_aux()
pacman::p_load(cluster, fmxdat)

corr <- cov2cor(sigma)
distmat <- ((1 - corr)/2)^0.5
distmat <- ((1 - corr)/2)^0.5
distmat[is.na(distmat)] <- 0     # fine tune how we want to deal with NA later 
cluster <- cluster::agnes(dist(distmat), method = "ward")

D <- dist(PCA_AllData)
hc <- hclust(D, method = 'average')
hcdata <- dendro_data_k(cluster, 4)
p <- plot_ggdendro(hcdata, direction = "lr", expand.y = 0.2)
cols <- c("#a9a9a9", "#1f77b4", "#ff7f0e", "#2ca02c", "#AD3636")
p <- plot_ggdendro(hcdata, direction = "tb", scale.color = cols,
    label.size = 2.5, branch.size = 0.5, expand.y = 0.2)
p <- p + theme_void() + expand_limits(x = c(-1, 32))
# p + labs(title = "Dendogram of EM Currencies", caption = "Dendogram created using Ward distances and AGNES clustering")
p
```


```{r pca, echo=FALSE}
PCA_AllData <- data
PCA_AllData <- spx


# remove Columns with only NA and columns must have at most 150 NA or zero points 
PCA_AllData <-  PCA_AllData[, colSums(is.na(PCA_AllData)) < nrow(PCA_AllData)] %>%   
    .[, colSums(is.na(.) | . == 0, na.rm = TRUE) <= 1000] 

# Impute missing values :) 
options(scipen = 999) 
PCA_AllData_with_date <- impute_missing_returns(PCA_AllData,
                               impute_returns_method = "Drawn_Distribution_Collective",
                               Seed = 1234)

PCA_AllData <- PCA_AllData_with_date %>% select(-date)

# save the supplementary variables' positions:
SuppPos <- grep("_CLOSE|_OPEN|_CLOSE|_BID|_ASK|_MID|_LOW|_HIGH|_VOL", colnames(PCA_AllData)) 


# PCA_AllData_nodate <- PCA_AllData[,-1]
df_PCA <- PCA(PCA_AllData, quanti.sup = SuppPos, graph = FALSE,  scale.unit = TRUE)


# detect outliers
# outlier(PCA_AllData, plot = TRUE, na.rm = TRUE)

# scree plot
fviz_screeplot(df_PCA, ncp = 10) 

fviz_pca_var(df_PCA, col.var = c("cos2", "contrib", "coord", 
    "x", "y")[1]) + scale_color_gradient2(low = "white", mid = "blue", 
    high = "red", midpoint = 0.5) + theme_minimal()

# Contributions of variables to PC1
fviz_contrib(df_PCA, choice = "var", axes = 1, top = 10)

# Contributions of variables to PC2
fviz_contrib(df_PCA, choice = "var", axes = 2, top = 10)
```


```{r garch, echo=FALSE}

demean = scale(PCA_AllData, center = TRUE, scale = TRUE)

demean <-  demean[, colSums(is.na(demean)) < nrow(demean)] # remove col with only na

date <- PCA_AllData_with_date[,1]

demean <- cbind(date, demean) %>% gather(Tickers, Return, -date) %>% tibble::as_tibble()  %>% dplyr::filter(date <= "2008-01-01")

xts_rtn <- demean %>% tbl2xts::tbl_xts(., cols_to_xts = "Return", spread_by = "Tickers")

gog_time_var_cor <- plotGOGARCH(xts_rtn)


garch_plot<- ggplot(gog_time_var_cor %>% filter(grepl("SPX_", Pairs), !grepl("_SPX", Pairs))) +
        geom_line(aes(x = date, y = Rho, colour = Pairs), size = 0.2) +
        theme_hc() +
        ggtitle("GARCH correlations to SP 500") +
        theme(legend.text=element_text(size=6), legend.title = element_blank())


```



## SP 500


```{r spx_dendrogram}
library(RcppRoll)

data_tr %>% ggplot() +
  geom_line(aes(date, value)) +
  facet_wrap(~name, scales = "free_y")

# spx <- data[1:10]
spx <- data_tr %>% filter(grepl("SPX", name))
spx <- spx %>% spread(name, value)


spx <- data[1:10]

lookback_period <- c(1,5,21,3*(1:4)*21)
nLookBack <- length(lookback_period)
nobs <- nrow(spx[,-1])
variance_gk <- matrix(NA,nobs,nLookBack)

#Extracting text after last period (.) in string
colnames(spx) <- sub('.*\\.',"",colnames(spx))
variance_data <- 
  spx %>% 
  as.data.frame() %>% 
  mutate(date = index(spx),
         c = log(SPX_PX_CLOSE_1D) - log(SPX_PX_OPEN),
         h = log(SPX_PX_HIGH) - log(SPX_PX_LOW),
         l = log(SPX_PX_LOW) - log(SPX_PX_OPEN)) %>% 
  mutate(GK = 0.5*(h-l)^2-(2*log(2)-1)*c^2)

for (j in 1:nLookBack) {
  variance_gk[,j] <- roll_meanr(lag(variance_data$GK),n = lookback_period[j])
}

colnames(variance_gk) <- paste0("GK_",lookback_period)

variance_gk <- data.frame(date=variance_data$date,variance_gk)

#Plot Garman-Klass volatility
variance_gk %>% 
  pivot_longer(cols = !date, names_to = "entity",values_to = "variance") %>% 
  ggplot(aes(x=date,y=sqrt(252)*sqrt(variance), group=entity))+
  geom_line(aes(color=entity))





xas <- spx[,c(1:2)] %>% 
  left_join(variance_gk %>% mutate(date = spx$date), by = "date")

         # SPX_PX_LAST_var = rollapply(spx$SPX_PX_LAST,width = 3, FUN = var, align = "left"))





pcaseries <- spx
PCA_AllData <- spx

# pcaseries <- all data 
# pcaseries must be in wide format
pcaseries <-  pcaseries[, colSums(is.na(pcaseries)) < nrow(pcaseries)]   # remove Columns with only NA
pcaseries[is.na(pcaseries)] <- 0

demean = scale(pcaseries[,-1], center = TRUE, scale = TRUE)
sigma <- cov(demean)

devtools::source_gist("https://gist.github.com/Nicktz/bd2614f8f8a551881a1dc3c11a1e7268")
cluster_aux()
pacman::p_load(cluster, fmxdat)

corr <- cov2cor(sigma)
distmat <- ((1 - corr)/2)^0.5
distmat <- ((1 - corr)/2)^0.5
distmat[is.na(distmat)] <- 0     # fine tune how we want to deal with NA later 
cluster <- cluster::agnes(dist(distmat), method = "ward")

D <- dist(PCA_AllData)
hc <- hclust(D, method = 'average')
hcdata <- dendro_data_k(cluster, 4)
p <- plot_ggdendro(hcdata, direction = "lr", expand.y = 0.2)
cols <- c("#a9a9a9", "#1f77b4", "#ff7f0e", "#2ca02c", "#AD3636")
p <- plot_ggdendro(hcdata, direction = "tb", scale.color = cols,
    label.size = 2.5, branch.size = 0.5, expand.y = 0.2)
p <- p + theme_void() + expand_limits(x = c(-1, 32))
# p + labs(title = "Dendogram of EM Currencies", caption = "Dendogram created using Ward distances and AGNES clustering")
p
```


```{r spx_pca, echo=FALSE}
PCA_AllData <- spx


# remove Columns with only NA and columns must have at most 150 NA or zero points 
PCA_AllData <-  PCA_AllData[, colSums(is.na(PCA_AllData)) < nrow(PCA_AllData)] %>%   
    .[, colSums(is.na(.) | . == 0, na.rm = TRUE) <= 1000] 

# Impute missing values :) 
options(scipen = 999) 
PCA_AllData_with_date <- impute_missing_returns(PCA_AllData,
                               impute_returns_method = "Drawn_Distribution_Collective",
                               Seed = 1234)

PCA_AllData <- PCA_AllData_with_date %>% select(-date)

# save the supplementary variables' positions:
SuppPos <- grep("_CLOSE|_OPEN|_CLOSE|_ASK|_MID|_HIGH|_VOL", colnames(PCA_AllData)) 


# PCA_AllData_nodate <- PCA_AllData[,-1]
df_PCA <- PCA(PCA_AllData, quanti.sup = SuppPos, graph = FALSE,  scale.unit = TRUE)


# detect outliers
# outlier(PCA_AllData, plot = TRUE, na.rm = TRUE)

# scree plot
fviz_screeplot(df_PCA, ncp = 10) 

fviz_pca_var(df_PCA, col.var = c("cos2", "contrib", "coord", 
    "x", "y")[1]) + scale_color_gradient2(low = "white", mid = "blue", 
    high = "red", midpoint = 0.5) + theme_minimal()

# Contributions of variables to PC1
fviz_contrib(df_PCA, choice = "var", axes = 1, top = 10)

# Contributions of variables to PC2
fviz_contrib(df_PCA, choice = "var", axes = 2, top = 10)
```


```{r spx_garch, echo=FALSE}

demean = scale(PCA_AllData, center = TRUE, scale = TRUE)

demean <-  demean[, colSums(is.na(demean)) < nrow(demean)] # remove col with only na

date <- PCA_AllData_with_date[,1]

demean <- cbind(date, demean) %>% gather(Tickers, Return, -date) %>% tibble::as_tibble()  %>% dplyr::filter(date <= "2008-01-01")

xts_rtn <- demean %>% tbl2xts::tbl_xts(., cols_to_xts = "Return", spread_by = "Tickers")

gog_time_var_cor <- plotGOGARCH(xts_rtn)


garch_plot <- 
  ggplot(gog_time_var_cor %>% 
           filter(grepl("SPX_PX_LAST_", Pairs),
                  !grepl("_SPX_PX_LAST", Pairs))) +
  geom_line(aes(x = date, y = Rho, colour = Pairs), size = 0.2) +
        theme_hc() +
        ggtitle("GARCH correlations to SP 500") +
        theme(legend.text=element_text(size=6), legend.title = element_blank())


```


```{r high_vs_low_vol_periods}

Idxs <- PCA_AllData_with_date %>% 
    gather(Tickers, Return, -date) %>% 
    filter(!is.na(Return)) %>%
    filter(Tickers !="SPX_PX_LAST") %>% 
    mutate(YearMonth = format(date, "%Y%B"))


# Consider only indexes with data from before 20080101, and use this as a common start date too...:
# Can you argue why? - beacuase of GFC
Idx_Cons <- Idxs %>% 
    group_by(Tickers) %>% 
    filter(date == first(date)) %>% 
    ungroup() %>% 
    filter(date < ymd(20080101)) %>%  
    pull(Tickers) %>% unique # make a list of all the tickers that exist pre-GFC

Idxs <- Idxs %>% 
    filter(Tickers %in% Idx_Cons) %>%  # only keep tickers that existed pre-GFC
    filter(date > ymd(20080101))

# Winzorising: mitigate the effect of extreme values
Idxs <- Idxs %>% 
    group_by(Tickers) %>% 
    mutate(Top = quantile(Return, 0.99), Bot = quantile(Return, 0.01)) %>% 
    mutate(Return = ifelse(Return > Top, Top, ifelse(Return < Bot, Bot, Return))) %>% 
    ungroup()

# do periods of high and low volatility in the rand affect the performance of South African bank return prices

spx <- PCA_AllData_with_date %>% 
    gather(Tickers, Return, -date) %>% 
    filter(date > ymd(20080101)) %>% 
    filter(Tickers == "SPX_PX_LAST")


spxSD <- spx %>% 
    mutate(YearMonth = format(date, "%Y%B")) %>% 
    group_by(YearMonth) %>% summarise(SD = sd(Return)*sqrt(52)) %>% 
  # Top Decile Quantile overall (highly volatile month for spx:
    mutate(TopQtile = quantile(SD, 0.8),
           BotQtile = quantile(SD, 0.2))


Hi_Vol <- spxSD %>% filter(SD > TopQtile) %>% pull(YearMonth)

Low_Vol <- spxSD %>% filter(SD < BotQtile) %>% pull(YearMonth)

perf_hi <- Perf_comparisons(Idxs, YMs = Hi_Vol, Alias = "High_Vol")

perf_lo <- Perf_comparisons(Idxs, YMs = Low_Vol, Alias = "Low_Vol")
```


```{r high, fig.cap = "Standard deviation and correlation ratio in periods of high Rand volatility \\label{high}"}
kable(perf_hi, caption = "Standard deviation and correlation ratio in periods of high volatility \\label{high}")
```


```{r low, fig.cap = "Standard deviation and correlation ratio in periods of low Rand volatility  \\label{low}"}
kable(perf_lo, caption = "Standard deviation and correlation ratio in periods of low volatility \\label{low}")
```


